

 → I/O multiplexing은 Blocking이 아니라 Non-Blocking에 더 가까운게 아닐까?


## Block & Non-Block
 - 처리되어야 하는 작업에 대한 제어권이 누구에게 있는가

＊ Block과 Non-Block은 함수 호출에 관해 호출자가 취하는 태도의 차이로 알아볼 수 있다
＊ Block : 호출자가 함수를 호출, 해당 함수가 실행, 결과값이 리턴될 때까지 기다린다

 - A 함수가 B 함수를 호출하면, 제어권을 A가 호출한 B에게 넘겨준다
① A 함수가 B 함수를 호출하면 B 함수에게 제어권을 넘긴다
② 제어권을 넘겨받은 B는 열심히 함수를 실행한다. A는 B에게 제어권을 넘겨주었기 때문에, 함수 실행을 잠시 멈춘다
③ B 함수는 실행이 끝나면 자신을 호출한 A에게 제어권을 돌려준다

＊ Non-Block : 호출자가 함수를 호출, 결과값 리턴을 기다리지 않고 바로 다음 코드 실행

 - A 함수가 B 함수를 호출해도 제어권은 A 함수인 자신이 가지고 있는다
① A 함수가 B 함수를 호출하면, B 함수는 실행되지만, 제어권은 A 함수가 그대로 가지고 있는다
② A 함수는 계속 제어권을 가지고 있기 때문에, B 함수를 호출한 이후에도 자신의 코드를 계속 실행

## Block I/O와 Non-Block I/O
＊ I/O : input/output – 데이터 입출력
 - I/O의 종류는 network(socket), file, pipe, device 등이 있음
 - socket : 네트워크 통신은 socket을 통해 데이터 입출력이 이뤄진다

＊ Block I/O
 - I/O 작업을 요청한 프로세스, 스레드는 요청이 완료될 때까지 블락됨

＊ Non-Block I/O
 - 블락되지 않고 즉시 리턴하기 때문에 스레드가 다른 작업을 수행할 수 있다
 - I/O 작업 완료는 어떻게 확인하는가?
① 완료되었는지 반복적으로 확인하기
 - 완료 시간과 완료를 확인한 시간 사이의 갭으로 인해 처리 속도가 느려질 수 있음
 - 하지만, 완료되었는지 반복적으로 확인하는 것은 cpu 낭비가 발생할 수 잇다
② I/O multiplexing(다중 입출력) 사용
 - select, poll, epoll, kqueue, IOCP(I/O completion port)
③ Callback/Signal 사용
 - POSIX AIO, LINUX AIO
 - 널리 사용되지는 않다
④ IO_Uring
 - Non-Block I/O를 통해 I/O 요청 완료 전에도 다른 일을 할 수 있다


## Sync & Async
＊ Sync
 - 요청을 보낸 후, 응답을 받아야만 다음 동작이 이뤄지는 방식
 - 모든 일이 순차적으로 실행
 - 동시에 똑같이 진행된다는 뜻을 가지고 있다
 - 설계가 간단하지만, 결과가 나오지 않는다면 다음 작업을 진행할 수 없음
＊ Async
 - 요청을 즉시 처리하지 않아도, 그 대기 시간동안 또 다른 동작이 이뤄지는 방식
 - 모든 일이 병렬적으로 실행
 - 동시에 똑같이 진행되지 않는다는 뜻을 가지고 있다
 - 작업들이 요청과 응답의 타이밍이 같지 않아도 된다
 - 설계가 복잡하지만, 결과가 나오지 않더라도 다른 작업을 병렬적으로 수행할 수 있다

☞ 버퍼 (Buffer)
 - 데이터를 한 곳에서 다른 곳으로 전송하는 동안 일시적으로 그 데이터를 보관하는 메모리의 영역
☞ 스레드 (Thread)
 - 프로그램이나 프로세스 내에서 실행되는 흐름의 단위
 - 일반적으로 한 프로그램에서는 하나의 스레드를 가지고 있다
 - 프로그램의 환경에 따라 둘 이상의 스레드를 동시에 실행할 수 있다
☞ 멀티프로세스, 멀티스레드
 - 두 가지 모두 여러 흐름이 동시에 진행된다는 공통점을 지님
 - 멀티프로세스는 각 프로세스에서 독립적으로 실행되며 각각의 메모리를 차지하고 있다
 - 멀티스레드는 프로세스 내의 메모리를 공유해 사용, 프로세스 간 전환 속도가 스레드보다 빠르다
☞병목현상 (Bottleneck)
 - 시스템의 성능이나 용량이 하나의 구성 요소로 인해 제한을 받는 현상

☞ Promise 객체
 - 비동기 작업을 맞이할 미래의 완료 또는 실패와 그 결과값을 나타냄
 - 프로미스 객체를 사용하면 비동기 메서드에서 마치 동기 메서드처럼 값을 반환할 수 있다
 - 최종 결과를 반환하는 것은 아니지만, 미래의 어떤 시점에 결과를 제공하겠다는 약속을 반환
 - 대기(pending) : 이행하지도 거부하지도 않은 초기의 상태
 - 이행(fulfilled) : 연산이 성공적으로 완료됨
 - 거부(rejected) : 연산의 실패
 - 프로미스가 대기에서 벗어나 이행, 거부가 된다면 프로미스가 처리되었다고 말한다
 - 리졸브(resolved) : 프로미스가 처리되었거나, 다른 프로미스의 상태에 맞춰 잠금 상태가 되었다는 의미를 나타냄


## WebServer & WAS(WebApplicationServer)

 거의 모든 웹 사이트가 정적, 동적을 모두 제공하기 때문에 두 서버를 모두 사용
정적 페이지, 동적 페이지를 처리할 때 서버 자원 소요량이 다르기 때문
 WS, WAS 두 가지가 함께 필요하며, 이 두 개의 서버를 동일한 HW 박스에서 가동 시키는 것도 충분히 가능한 구성
 - 서비스 운용 관리 측면에서 하나의 HW 박스에 구성하는 것이 조금 더 간편한 방식이기 때문
 - 하나의 HW 박스에 두 서버를 모두 탑재도 가능하지만
 - HW 박스를 분리하여 구성하면 메모리 효율을 더 높일 수 있다
 - WS와 WAS간의 메모리 사이즈 비율을 조절할 수 있기 때문 (이를 위해선 해당 웹 사이트 트래픽 중 요청 건수 비율을 분석해야 함)

 통상적으로 일컫는 서버는 두 가지로 구분
1. 웹 서버 (WS)
2. 웹 어플리케이션 서버 (WAS)



이렇게 두 가지로 나눠서 사용하는 이유는 효율성 때문
WS는 정적인 컨텐츠 처리, WAS는 동적인 컨텐츠 처리를 담당

＊ 정적 (Static)
 - 만들어놓은 것 그대로를 제공하는 자체를 정적이라고 함
 - ex) HTML 템플릿 작성 후 홈페이지를 열어보면 이 자체를 정적 페이지라고 함
 - 웹 사이트 만들기를 처음 시작 단계로 함
 - 다른 컴퓨터나 클라이언트에서 접속해도 항상 같은 페이지를 보여주는 것

＊ 동적 (Dynamic)
 - 상호작용을 통한 데이터 처리가 필요한 경우 동적 페이지라 함
 - 데이터베이스 처리가 필요한 경우를 ‘동적’이란 말을 붙음
 - 사용자의 ‘요청’에 의해 데이터 가공처리 후 보여지는 웹 페이지

1. WS
 - 클라이언트가 요청한 정적인 컨텐츠를 HTTP를 통해 제공해주는 서버
 - 클라이언트로부터 들어온 요청에 대해 사용자 인증을 처리하는 역할
 - 요청한 파일이 없거나 문제가 발생하면 특정한 코드 값을 전달 (ex 404)
 - 주로 정적인 페이지 HTML, 이미지, CSS, 자바스크립트 파일을 웹 클라이언트에 제공
 - 동적 페이지처리가 필요할 경우 WAS에 처리를 넘김

☞ 정적인 컨텐츠 처리시 동적 컨텐츠는 어떻게 처리하나
 - 동적인 요청이 발생시 이 요청을 웹 서버에서 처리 불가능
 - 컨테이너로 보내주는 역할을 함

※ 웹 서버는 정적 처리만 가능
 - 똥적 처리가 불가능하기 때문에 이를 해결하기 위해 요청을 보냄
 - HTML 페이지 자체에서는 서버에 저장된 데이터를 가져오거나 저장이 불가능
 - 요청을 통해서 데이터를 가져오거나 저장해야 함
 - NGINX, APACHE, Lighttpd, IIS 등이 있다

※ 컨테이너 (Container)
 - 서블릿의 생명주기를 관리하고 JSP를 서블릿으로 변환하는 기능을 지님

 - 컨테이너의 종류 2가지 (서블릿 컨테이너, JSP 컨테이너)
 - 서블릿 컨테이너와 JSP 컨테이너는 같은 개념
 - JSP가 PHP처럼 스크립트 형식으로 동작하지 않고
 - 서블릿으로 변경된 이후에 실행되기 때문
 - JSP를 서블릿으로 컴파일 해주는 것이 JSP 엔진
 
 - 서블릿 : 서블릿은 JAVA로 구현된 CGI (자바를 사용하여 웹 페이지를 동적으로 생성하는 서버측 프로그램을 의미)
 - CGI (Common Gateway Interface) : 웹 서버와 프로그램 간의 교환 방식을 의미 (정적 처리를 하는 웹 서버와 컨테이너를 연결하기 위한 통신 장치)


 - JSP (Java Server Pages) : 자바 서버 페이지는 HTML 내에 자바 코드를 삽입하여 웹 서버에서 동적으로 웹 페이지를 생성하여 웹 브라우저에 돌려주는 서버 사이드 스크립트 언어

＊ JSP 기본 동작 구조
 - 클라이언트에서 서비스 요청되면 JSP 실행
 - JSP는 웹 어플리케이션 서버의 서블릿 컨테이너에서 서블릿 원시코드로 변환
 - 서블릿 원시코드 컴파일
 - HTML 형태로 클라이언트에 돌려줌

2. WAS
 - 웹 서버로부터 오는 동적인 요청을 처리하는 서버
 - 처리 결과를 다시 웹 서버로 반환
 - 인터넷 사의 HTTP를 통해 사용자 컴퓨터나 장치에 어플리케이션을 수행하는 미들웨어
 - 웹서버 + 컨테이너로 이뤄진 서버로 생각
 - 동적 페이지 생성을 위한 프로그램 실행과 데이터베이스 연동 기능을 처리

※ WAS는 동적 기능만을 수행
 - 프로그램 실행 환경과 데이터베이스 접속 기능을 제공
 - 여러 개의 트랜잭션을 관리
 - 업무를 처리하는 비즈니스 로직 수행
 - 아파치 톰캣, 제우스, 제티, 레진 등이 있다


## Microservices와 Monolitihic Architecture




### 모놀리틱 아키텍처 (Monolithic Architecture)

 - 전통의 아키텍처를 지칭
 - 소프트웨어의 모든 구성요소가 한 프로젝트에 통합되어있는 형태
 - 모든 프로세스가 긴밀히 결합되고 단일 서비스로 실행
 - 한 프로세스에 대한 수요가 급증하면 해당 아키텍처 전체를 확장해야 함

☞ 장점
 - 어떤 서비스든지 개발 환경이 같아 복잡하지 않음
 - 쉽게 고가용성 서버 환경을 만들 수 있다
 - 같은 어플리케이션으로 서버를 하나 더 만들면 되기 때문
 - End-to-End 테스트가 용이
 
☞ 단점
 - 한 프로젝트의 크기가 너무 크다
 - 어플리케이션 구동시간이 늘어나고, 빌드와 배포 시간도 길어진다
 - 조그마한 수정사항이 있어도 전체를 다시 빌드하고 배포해야 함
 - 많은 양의 코드가 몰려있어 모든 개발자가 이해하기 힘들고, 유지보수도 어려움
 - 일부 오류가 전체 영향을 미친다
 - 기능별로 알맞은 기술, 언어, 프레임워크 선택이 까다롭다

### 마이크로 서비스 (Micro Serivce)

 - 하나의 큰 애플리케이션을 여러 개의 작은 서비스 유닛으로 쪼개 변경과 조합이 가능하도록 만든 아키텍처
 - 각 마이크로서비스는 상호 통신이 가능하며, 이를 통해 전체 서비스를 구성
 - 각 애플리케이션이 독립적인 구성 요소로 구축
 - 경량 API를 사용하여 잘 정의된 인터페이스를 통해 통신한다
 - 독립적으로 실행되기 때문에 애플리케이션의 특정 기능에 대한 수요를 충족하도록 각각의 서비스를 업데이트, 배포 및 확장할 수 있음

☞ 장점
 - 기능별로 마이크로서비스를 개발
 - 작업 할당을 서비스 단위로 하면 개발자가 해당 부분을 온전히 이해할 수 있음
 - 새로 추가, 수정된 마이크로서비스만 빠르게 빌드, 배포가 가능
 - 각 서비스에 따라 개별적으로 서버를 나눌 수 있어 메모리 및 cpu 관리에 효율적
 - 모듈끼리 RPC, Message-driven을 이용하여 통신하기 때문에 각 서비스의 개발 속도가 증가
 - 해당 기능에 맞는 기술, 언어 등을 선택하여 사용 가능
 - 일부분 오류가 있으면 해당 기능에만 오류가 발생
 - 오류가 발생한 부분만 고쳐 정상 가동할 수 있음

☞ 단점
 - 작은 여러 서비스가 분산되어 모니터링이 힘듦
 - 서비스 간 호출 시 REST API 사용으로 인한 통신비용, 지연시간이 증가
 - 서비스 분산으로 인해 트랜잭션 관리, 장애 추적 및 테스트 등이 쉽지 않다
 - 서비스마다 DB가 분리되어 데이터 조회가 어렵고 중복이 발생
 - 서로를 호출하는 전체 서비스가 이뤄져 다른 서비스 호출 코드가 추가
 - 호출 코드 모놀리식 아키텍쳐보다 개발이 까다롭다
 - 전체 서비스가 커짐에 따라 복잡도가 기하급수적으로 늘어날 수 있다
 - 통신 관련 오류가 잦다


## Multi Module & MSA

### 멀티모듈 (Multi Module)
 - 한 프로젝트 안에 라이브러리처럼 사용 가능한 상태로 모듈들을 구성하고
 - 그 모듈들을 다른 모듈에서 가져다 쓸 수 있도록 만드는 것

 - 대부분의 서비스는 단일 프로젝트로 구성되는 일이 없음
 - 아무리 작게 구성하려해도 일정 수준 이상의 트래픽을 감당하기 위해서는 사용자와 접점을 담당하는 서버 DB와의 접점을 담당하는 서버로 구분하여 구성해야 함
＊ 멀티모듈
 - 공통으로 사용하는 클래스를 모듈로 만들어 가져다 쓰는 방식
 - 중복 관리 포인트가 발생하지 않음
 - 언격 저장소에 배포하지 않아도 됨


## 도메인별로 프로젝트를 구성하는 방식
☞ 모노리스 (가장 단순한 단일 프로젝트)
☞ 멀티모듈을 layer별로 구성(core, service, api 등) → 모노리스 (하나의 JVM)
☞ 멀티모듈을 도메인별로 구성하지만 → 모노리스 (하나의 JVM)
☞ 멀티모듈을 도메인별로 구성 → MSA (여러 JVM)

① 모노리스
☞ 장점
 - 가장 단순한 형태로 쉽고 빠르게 개발

☞ 단점
 - scale up이 어렵다
 - 특정 서비스만 정교하게 확장하고자 할 때, 프로젝트를 통째로 늘려야 함
 - 오류 전파가 쉽다
 - 하나의 서비스에서 다른 컴포넌트를 가져다 사용하는 만큼, 의존성 관리가 잘 되지 않음
 - 하나의 컴포넌트에서 오류 발생 시, 관련 서비스들이 모두 장애를 겪을 수 있음

② layer별로 구성한 멀티 모듈 프로젝트
☞ 장점
 - 흔하게 볼 수 있는 프로젝트 구조
 - 개발이나 설정이 쉬운 편
 - 단순 모노리스에 비해 패키지 의존성 관리를 더 신경쓰면서 개발해야 함
 - 프로젝트 구조상 패키지 의존성이나 모듈간 의존성을 주의
 - 모노리스에 비해 의존성이 더 잘 정리된다

☞ 단점
 - 패키지 의존성 관리를 잘 못할 경우, 빌드 꼬임 발생, 더 무거운 프로그램으로 변모
 - 의무적으로 의존성 관리를 해줘야 하지만, 계속 신경을 써줘야 함
 - 도메인 간 분리가 어려울 수 있음
 - 해당 layer의 도메인이 다른 layer 도메인과 어떻게 이어지는지 알기 어려움

③ 멀티모듈을 도메인별로 구성하지만 → 모노리스 (하나의 JVM)
☞ 장점
 - 프로젝트가 서비스 단위로 나뉨 (해당 서비스 모듈에 대한 책임자가 명확)
 - 프로젝트 내에서 파일 찾기가 쉽다 (대부분 같은 도메인 내에서 해결되기 때문)
 - 새로운 서비스를 추가할 때, 모듈을 새로 생성해서 작업 (기존 파일들과 엮이지 않고 분리된 환경에서 개발이 가능)

☞ 단점
 - 여러 개의 서비스 모듈을 하나의 JVM에 띄우기 위한 추가 작업이 필요
 - 다른 서비스 모듈 하위 Spring bean을 등록하기 위한 추가 작업
 - 서비스 모듈별 설정파일과 패키지 의존성 관리에도 신경을 써야 함

④ 멀티모듈을 도메인별로 구성 → MSA (여러 JVM)
☞ 장점
 - 서비스 간 의존도가 가장 낮은 구조
 - 서비스별로 scale up 하기 용이하다

☞ 단점
 - 서비스 간 통신에 신경을 많이 써야 함
 - 데이터 동기화 문제, 메시지 큐 관리, 서킷 브레이커, 로드밸런싱, 분산 DB 등등 오버헤드가 발생


## NginX & Apache


＊ NginX (설계 아키텍처의 차이)
 - 이벤트 중심 접근 방식으로 하나의 스레드 내에서 여러 요청을 처리
 - 비동기 Event-Driven 구조 : Event Handler에서 비동기 방식으로 먼저 처리되는 요청을 진행
 - 코어 모듈이 Apache보다 적은 리소스로도 많은 트래픽을 효율적으로 처리 가능

＊ Apache (설계 아키텍처의 차이)
 - 프로세스 기반 접근 방식으로 하나의 스레드가 하나의 요청을 처리
 - 매 요청마다 스레드를 생성 및 할당해야 하기 때문에 리소스를 많이 잡아먹는다



＊ NginX & Apache (성능 차이)
 - 두 웹서버 모두 정적 및 동적 컨텐츠를 제공하는 방식이 다르다

☞ 정적 컨텐츠
 - 서버 PC의 디스크에 저장하는 파일 기반 방법으로 정적 컨텐츠 제공
 - 설계 아키텍처 구조상 NginX가 적은 비용으로 효율적 제공

 ☞ 동적 컨텐츠
 - 두 웹 서버 모두 서버 자체에서 동적 컨텐츠 처리 가능
 - NginX는 SCGI 핸들러와 FastCGI 모듈을 사용해서 동적 컨텐츠를 제공
 - 동적 컨텐츠는 두 웹서버 성능이 비슷

＊ NginX (OS 지원 여부)
 - 거의 모든 Unix 계열 OS 지원
 - Windows는 부분적으로 지원

＊ Apache (OS 지원 여부)
 - Linux 및 BSD를 포함한 모든 Unix 계열 OS 지원
 - Windows 모두 지원

＊ NginX (분산 / 중앙 집중식 구성)
 - 추가 구성을 허용하지 않음
 - 권한이 없는 사용자가 웹 사이트의 특정 측면을 제어할 수 없지만, 추가 구성을 제공하지 않음으로써 성능 향상
 - 디렉터리 구성을 허용하지 않음으로 .htaccess 파일을 검색하고 사용자가 만든 요구 사항을 해석할 필요가 없어
 - Apahce보다 빠르게 요청 처리가 가능

＊ Apache (분산 / 중앙 집중식 구성)
 - .htaccess 파일을 통해 디렉터리 별로 추가 구성을 허용
 - 추가 구성 허용으로 인해 권한이 없는 사용자가 웹 사이트의 특정 측면을 제어할 수 있음

＊ NginX (요청 처리 및 해석 방법)
 - 요청을 해석하기 위해 URI를 전달
 - URI로 전달함으로써 웹 서버뿐 아니라 프록시 서버, 로드 밸런서 및 HTTP 캐시로 쉽게 동작 가능
 - 서버에서 클라이언트로 데이터가 전송되는 속도가 Apache보다 더 빠름

＊ Apache (요청 처리 및 해석 방법
 - 요청을 해석하기 위해 파일 시스템 위치 전달
 - URI 위치를 사용하지만 일반적으로 더 추상적인 디렉터리 구조를 사용

＊ NginX (기능 모듈의 차이)
 - 타 사 플러그인 과정으로 선택되고 컴파일되기 때문에 동적으로 모듈을 로드할 수 없음
 - 사용하려는 기능만 선택해서 서버를 실행 (가볍다)

＊ Apache (기능 모듈의 차이)
 - 동적으로 로드 가능한 다양한 60개의 공식 모듈을 제공
 - 모든 모듈을 가지고 서버가 실행되지만 실제 사용되는 모듈은 소수 (무거움)

＊ NginX (유연성)
 - 아직까지 동적 모듈과 로딩을 지원하지 않음

＊ Apache (유연성)
 - 동적 모듈과 로딩을 지원함

＊ NginX & Apache (보안)
 - 두 웹서버 모두 C언어 기반으로 확장된 보안을 제공
 - 하지만, NginX 코드가 더 작기 때문에 미래 지향적인 보안 관점에서 장점을 지님
 - 비슷하지만 NginX가 조금 더 안전한 것으로 간주

※ 두 서버를 어떤 상황에서 사용해야 하나?
 - Apache는 .htacess 파일을 제공하기 때문에 이를 활용
 - NginX에게 없는 핵심 모듈을 사용할 경우 Apache를 사용
 - 빠른 정적 컨텐츠를 처리하고 싶능 경우 NginX
 - 대용량 트래픽을 처리하는 웹 사이트의 경우 NginX
또한, 두 서버를 함께 사용 가능 (Apache 앞단 & NginX 프록시 서버로 활용)


## Servlet & Netty

☞ Spring MVC
 - 웹 통신의 핵심은 Servlet API이며, 이를 구현한 서블릿 컨테이너(Tomcat, Jetty)를 기반으로 함
 - Servlet은 통신이 Client → Server로 이동하는 방법이 매우 엄격
 - Servlet : 웹 프로그래밍에서 Client의 요청을 처리 후 결과값 전송하는 Servlet 클래스의 구현 규칙을 지킨 자바 프로그래밍 기술

☞ Webflux
 - spring mvc와 반대로 servlet에 의존하지 않는다
 - servlet을 기반으로 구축, 구축하지 않은 서버(Netty, Undertow)를 모두 사용할 수 있음

☞ Netty
 - 비동기 이벤트 기반 네트워크 응용 프로그램 프레임워크
 - asynchronous event-driven network application framework
 - 신속한 개발과 유지보수가 가능한 고성능기능을 위한 framework
 - 2개의 이벤트 루프를 사용
 - boss & worker
    └ boss는 들어오는 연결을 수락, 재갇ㄱ에게 등록
    └ data가 사용가능하면, worker에게 알리고 데이터 처리

☞ 서버는 어떻게 작동하는가?
 - 요청하기 전 client와 server는 자신의 소켓(포트)에 바인딩하여 연결을 설정
 - 서버가 소켓에서 수신&대기하는 동안, client가 연결 요청을 보낸다
 - 연결이 설정되면, client가 data를 전송하기 시작
 - server는 이를 처리하고 response를 보냄
 - 이후 연결을 닫는다
 - 대부분의 시간은 연결 설정과 데이터 수신을 기다리는데 소요

＊ Blocking IO

 - 스레드가 하나의 connection을 관리하고 있으므로, 하나의 open connection만 있을 수 있다
 - 다른 client는 연결을 시도하는 동안, 이미 open된 connection이 닫힐 때까지 아무 일도 일어나지 않음

＊ Threaded-Blocking IO (쓰레드 차단 IO)

 - 새로운 모든 연결을 새로운 소켓에 binding하고 data를 처리할 새로운 thread를 만든다
 - clinet → server socket에 연결 요청시, 통신할 new socket을 다시 내보낸다
 - CPU, OS 제한에 따라 상당히 많은 thread를 만들 수 있기 때문에 충분
 - 최대 thread 수의 limit에 도달할 때까지 여러 연결을 처리 가능
 - 각 thread는 memory 할당이 필요해서, 동시에 연결이 진행동안 서버 성능이 저하된다

＊ Non-Blocking IO

 - thread를 연결하기 위해 binding하는 대신, data를 buffer에서 읽을 준비가 되면 알림이 전송된다 (이벤트 루프)
 - NIO는 data를 read / write할 때, 스트림 대신 버퍼를 사용
    └ 요청할 모든 data가 다 준비되어 수신하는 것이 아님
    └ 생성이 될 때마다 처리가 된다
 - 이 매커니즘을 사용하면 하나의 thread로 여러 연결을 처리할 수 있다
 - 이것이 IO를 기다리는 동안 thread가 차단되지 않는 방법이다
 - thread는 new data의 도착에 대한 알림을 받을 때만 buffer를 읽는다 (이벤트 루프)
 - 몇개의 thread만으로 동시에 많은 연결을 처리할 수 있다

＊ Callback, Reactive, Reactive Core
 - 외부 리소스를 기다리는 동안, 요청되는 스레드를 차단하지 않는 것
 - data가 스트리밍되는 동안 대기
 - data가 도착했다는 알림을 받고 싶을 때 사용

## 로드 밸런싱 (Load Balancing)
 - 부하분산 또는 로드 밸런싱은 컴퓨터 네트워크 기술의 일종으로 둘 혹은 셋 이상의 중앙처리장치 혹은 저장장치와 같은 컴퓨터 자원들에게 작업을 나누는 것을 의미
 - 즉, 여러 서버가 분산 처리하는 것

☞ 종류
 - L4 : Transport 계층을 사용, IP 주소와 포트 번호 부하 분산이 가능 (NLB)
 - L7 : Application 계층을 사용, URL 또는 HTTP 헤더에서 부하 분산이 가능 (ALB)

＊ NLB (Network LoadBalancer)


 - Client IP와 서버사이에 서버로 들어오는 트래픽은 Load Balancer를 통하고
 - 나가는 트래픽은 Client IP와 직접 통신
 - NLB는 Security Group 적용이 되지 않아서 서버에 적용된 Security Group에서 보안이 가능
 - Client → Server에서 Access 제한 가능
 - NLB는 할당한 Elastic IP를 Static IP로 사용이 가능
 - DNS Name과 IP주소 모두 사용이 가능
 - Name Server 또는 Route 53에서 A Record 사용이 가능

＊ ALB (Application LoadBalancer)


 - Reverse Proxy대로 Client IP와 서버 사이에 들어오고 나가는 트래픽이 모두 Load Balancer와 통신
 - CLB / ALB는 Security Group을 통한 보안이 가능
 - Client → Load Balancer의 Access 제한 가능
 - ALB / CLB는 IP 주소가 변동되기 때문에 Client에서 Access할 ELB의 DNS Name을 이용해야 함
 - Name Server 또는 Route 53에서 CName을 사용해야 Domain Name 연동이 가능

### Load Balancing Algorithm 종류
☞ 라운드 로빈 방식 (RR)
 - 클라이언트로부터 받은 요청을 로드밸런싱 대상 서버에 순서대로 할당
 - 첫 번째 요청은 첫 번째 서버, N 번째 요청은 N 번째 서버에 할당
 - 로드밸러닝 대상 서버의 성능이 동일하고 처리 시간이 짧은 애플리케이션의 경우, 균등하게 분산이 이뤄지기 때문에 이 방식을 사용

☞ 가중 라운드 로빈 방식 (WRR)
 - 실제 서버에 서로 다른 처리 용량을 지정할 수 있음
 - 각 서버에 가중치를 부여할 수 있으며, 여기 지정한 정수값을 통해 처리 용량을 정함

☞ 최소 연결 방식
 - 연결 수가 가장 적은 서버에서 네트워크 연결방향을 정함
 - 동적인 분산 알고리즘으로 각 서버에 대한 현재 연결 수를 동적으로 카운트
 - 동적으로 변하는 요청에 대한 부하를 분산시킬 수 있다


## Forward Proxy & Reverse Proxy

☞ Forward Proxy
 - 사용자가 google.com에 연결하고자 하면 사용자 PC가 직접 연결하는게 아니라
 - 포워드프록시 서버가 요청을 받아 google.com에 연결
 - 그 결과를 클라이언트에 전달(forward) 해 줌

 - 포워드프록시의 경우 대개 캐쉬 기능이 있어 자주 사용되는 컨텐츠에 성능이 향상되며
 - 정해진 사이트만 연결하게 설정하는데도 유용하다
 - 웹 환경을 제한할 수 있어 보안이 중요한 기업 환경 등에서 많이 사용




☞ Reverse Proxy
 - A라는 회사가 example.com이라는 고객용 웹 서비스를 만듦
 - 이를 서비스하기 위해 리버스프록시가 필요

 - 리버스프록시로 웹 서버를 설정할 경우
 - 사용자가 example.com 웹 서비스에 데이터를 요청
 - Reverse Proxy는 이 요청을 받아 내부서버(WAS)에서 데이터를 받은 후
 - 이 데이터를 다시 사용자에게 전달


 - 대부분의 WAS는 WS 기능을 제공하므로 Reverse Proxy가 없이
 - 내부 WAS가 직접 서비스를 제공해도 된다

### Reverse Proxy의 장점
① 보안
 - 기업의 네트워크 환경은 DMZ가 존재 (내부 네트워크와 외부 내트워크 사이 공간)
 - 리버스 프록시로 동작하는 웹 서버는 내부 WAS와 연결하도록 설정
 - 웹 서버가 해킹당해도 2차로 방화벽을 다시 뚫어야 해 보안에 강하다
 - 특히 Red Hat이나 CentOS라면 SELinux를 켜 놓으면 ESLinux의 강제 접근 통제에 따라 웹 서버는 사전 정해진 포트만 접근할 수 있으므로 2차 피해를 최소화 할 수 있다

② 속도와 안정성
 - 캐시 서버이기 때문에 속도와 안정성이 존재
 - CDN을 연동한다면 DDOS 공격을 효과적으로 방어하고 서비스를 안정적으로 제공

③ 신뢰성 증대
 - 리버스 프록시를 cluster로 구성하면, 가용성을 높일 수 있고
 - 사용자가 증가하는 상황에 맞게 WS나 WAS를 유연하게 늘릴 수 있다
 - 리버스 포록시 앞에 L4나 LodaBalance를 붙이면 RR이나 Least Connection 등 상황에 맞는 분배 알고리즘을 적용해 신뢰성을 높일 수 있음


## CDN 콘텐츠 전송 네트워크
 - 데이터 사용량이 많은 애플리케이션의 웹 페이지 로드 속도를 높이는 상호 연결된 서버 네트워크
 - CDN은 콘텐츠 전송 네트워크 또는 콘텐츠 배포 네트워크를 의미할 수 있음
 - 사용자가 웹 사이트를 방문할 때, 해당 웹 사이트 서버의 데이터는 사용자 컴퓨터에 도달하기 위해 인터넷을 통해 이동해야 함
 - 사용자가 해당 서버에 멀리 떨어져 있는 경우 대용량 데이터를 로드하는데 시간이 걸림
 - 대신 가까운 CDN 서버에 미리 저장하여, 컴퓨터 도달하는데 시간을 단축시킴

 - 대기 시간을 줄이거나 네트워크 설계로 인한 통신지연을 줄이는 목적을 지님
 - Client와 Web Server 사이에 중간 서버를 두어 효율성을 높ㅇ임
 - 이러한 CDN 서버는 Client-Server 통신의 일부를 관리
 - 웹 서버에 대한 웹 트래픽을 줄이고, 대역폭 소비를 줄이고, 애플리케이션의 사용자 환경을 개선

☞ 장점
 - 페이지 로드 시간 단축
   └ 페이지 로드 시간이 너무 느리면 웹 사이트 트래픽이 감소
   └ CDN은 반송률을 줄이고 사용자가 사이트에서 보내는 시간을 늘릴 수 있다
  - 대역폭 비용 절감
   └ 네트워크를 통해 들어오는 사이트 요청은 대역폭 비용이 높다
   └ 캐싱 및 최적화를 통해 CDN은 origin 서버가 제공해야하는 데이터 양을 줄임
 - 콘텐츠 가용성 제고
   └ 한 번에 너무 많은 사용자 방문시 오류 발생으로 웹 사이트가 중단될 수 있다
   └ CDN 서비스는 더 많은 웹 트래픽을 처리하고 웹 서버의 로드를 줄일 수 있음
   └ 하나 이상의 CDN 서버가 오프라인으로 전환되면, 해당 서버 서비스 중단되지 않도록 유지
 - 웹 사이트 보안 강화
   └ CDN은 여러 중간 서버 간에 로드를 분산하여 오리진 서버에 미치는 영향을 줄여 DDoS 공격에 유연하게 대처할 수 있음

☞ CDN 동작 방법
＊ 캐싱
 - 더 빠른  데이터 액세스를 위해 동일한 데이터의 여러 복사본을 저장하는 프로세스
 - 지리적으로 멀리 떨어진 웹 사이트 방문자는 사이트에서 정적 웹 콘텐츠를 처음 요청
 - 요청이 웹 애플리케이션 서버 또는 오리진 서버에 도달
 - 오리진 서버는 원격 방문자에게 응답을 보냄
 - 또한, 해당 방문자와 지리적으로 가장 가까운 CDN POP에 응답 복사본을 보냄
 - CDN POP 서버는 복사본을 캐싱된 파일로 저장
 - 다음에 해당 방문자 또는 다른 방문자가 동일 요청을 하면 캐싱 서버가 응답을 보냄


＊ 동적 가속
 - 웹 애플리케이션과 클라이언트 사이의 중개 CDN 서버로 인해 발생하는 동적 웹 콘텐츠 요청에 대한 서버 응답 시간을 단축하는 것
 - 지능형 라우팅 알고리즘
 - 오리진에 대한 지리적 근접성
 - 클라이언트 요청을 처리할 수 있으므로 클라이언트 요청을 줄일 수 있다

＊ 엣지 로직 계산
 - 클라이언트와 서버 간의 통신을 단순화하는 논리적 계산을 수행하도록 CDN 엣지 서버를 프로그래밍할 수 있습니다
 - 사용자 요청을 검사하고 캐싱 동작을 수정
 - 잘못된 사용자 요청을 확인하고 처리
 - 응답하기 전에 콘텐츠를 수정하거나 최적화


## E-Tag (Entity Tag)
 
 웹 서버와 브라우저가 캐시된 구성요소의 유효성을 확인하기 위해 사용하는 매커니즘
우리가 사용하는 캐시가 유효한지 검증하기 위해 E-Tag를 사용한다
검증 헤더로 Last-Modified, E-Tag가 있다

 - 서버의 리소스 변경
 - 저장해 놓은 캐시의 데이터와 서버의 리소스 데이터의 값이 다름
 - 캐시가 서버에게 리소스가 변경되었는지 안되었는지 확인
 - E-Tag를 통한 캐시 유효성 검사

☞ 장점
 - 불필요한 요청 트래픽을 감소
 - 요청에 대한 빠른 응답을 지원
 - 서버에 영향을 주지 않는 HTTP 메서드 혹은 로직을 지원 
 - 이러한 요청 트래픽 감소는 부가적으로 DB 트랜잭션을 감소시킬 수 있다


# 운영체제(OS)
## 프로세스(Process)
### 1. 프로그램 vs 프로세스
|프로그램|프로세스|
|:---:|:---:|
|저장장치에 저장되어 있는 정적인 상태|실행을 위해 메모리에 올라온 동적인 상태|
|"짠다", "작성한다"|"실행한다"|
|프로그램 + 프로세스 제어 블록|프로세스 - 프로세스 제어 블록|

> 프로그램 : 컴퓨터에서 실행될 때 특정 작업을 수행하는 일련의 명령어들의 모음(집합)<br>
> 프로세스 : 컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램<br>
> 프로세스 제어 블록 : 특정한 프로세스를 관리할 필요가 있는 정보를 포함하는 운영체제 커널의 자료구조<br>
> 커널 : 운영체제의 주요 구성 요소이며 컴퓨터 하드웨어와 프로세스를 잇는 핵심 인터페이스

### 2. 프로세스 구조
|영역|설명|
|:---:|:---:|
|코드 영역|<ul><li>프로그램의 본문이 기술된 곳으로 텍스트 영역</li></ul><ul><li>읽기 전용</li></ul>|
|데이터 영역|<ul><li>코드가 실행되면서 사용하는 변수나 파일 등의 각종 데이터를 모아놓은 곳</li></ul><ul><li>읽기/쓰기</li></ul>|
|스택 영역|<ul><li>운영체제가 프로세스를 실행하기 위해 부수적으로 필요한 데이터를 모아놓은 곳</li></ul><ul><li>숨김 영역</li></ul>|

### 3. 프로세스 활성 상태(Active Status)

<ul><li>생성 상태</li></ul>

```
생성 상태(Create Status)는 프로그램이 메모리에 올라오고 운영체제로부터 프로세스 제어블록을 할당받은 상태이다. 
생성된 프로세스는 바로 실행되는 것이 아니라 준비 상태에서 자기 순서를 기다리며, 프로세스 제어 블록도 같이 준비 상태로 옮겨진다.
```

<ul><li>준비 상태</li></ul>

```
준비 상태(Ready Status)는 실행 대기 중인 모든 프로세스가 자기 순서를 기다리는 상태이다. 
프로세스 제어 블록은 준비 큐(Ready Queue)에서 기다리며 CPU 스케줄러에 의해 관리된다. 
CPU 스케줄러는 준비 상태에서 큐를 몇 개 운영할지, 큐에 있는 어떤 프로세스의 프로세스 제어 블록을 실행 상태로 보낼지를 결정한다.
실제로는 다수의 준비 큐가 운영된다.
```

<ul><li>실행 상태</li></ul>

```
실행 상태(Running Status)는 프로세스가 CPU를 할당받아 실행되는 상태이다.
준비 상태에 있는 많은 프로세스 중 실행 상태에 들어가는 프로세스는 CPU의 개수 만큼이다.
실행 상태에 있는 프로세스는 자신에게 주어진 시간, 즉 타임 슬라이스 동안만 작업할 수 있다.
그 시간을 다 사용하면 timeout(PID)가 실행된다.
timeout(PID)는 프로세스 제어 블록을 실행 상태에서 준비 상태로 옮긴다.
만약 실행 상태 동안 작업이 완료되면 exit(PID)가 실행되어 프로세스가 정상 종료된다.
실행 상태에 있는 프로세스가 입출력을 요청하면 CPU는 입출력 관리자에게 입출력을 요청하고 block(PID)를 실행한다.
block(PID)는 입출력이 완료될 때까지 작업을 진행할 수 없기 때무에 해당 프로세스를 대기 상태로 옮긴다.
CPU 스케줄러는 새로운 프로세스를 실행 상태로 가져온다(dispatch)
```

<ul><li>대기 상태</li></ul>

```
대기 상태(Blocking Status)는 실행 상태에 있는 프로세스가 입출력을 요청하면 입출력이 완료될 때까지 기다리는 상태로 'wait status'라고도 한다.
대기 상태는 작업의 효율을 위해 만들어진 것으로, 대기 상태의 프로세스는 입출력장치별로 마련된 큐에서 기다린다.
입출력이 완료되면 인터럽트가 발생하고, 대기 상태에 있는 여러 프로세스 중 해당 인터럽트로 깨어날 프로세스를 찾는데 이것이 wakeup(PID)이다.
wakeup(PID)로 해당 프로세스의 프로세스 제어 블록이 준비 상태로 이동하게 된다.
어떤 프로세스가 대기 상태에서 준비 상태로 이동하는 것은 인터럽트 때문이다.
인터럽트는 입출력으로 발생하지만 어떤 이벤트에 의해 발생하기도 한다.
```

<ul><li>완료 상태</li></ul>

```
완료 상태(Terminate Status)는 프로세스가 종료되는 상태이다.
완료 상태에서는 코드와 사용했던 데이터를 메모리에서 삭제하고 프로세스 제어 블록을 폐기한다.
정상적인 종료는 간단히 exit()로 처리한다.
만약 오류나 다른 프로세스에 의해 비정상적으로 종료되는 강제종료(abort)를 만나면 디버깅하기 위해 강제 종료 직전의 메모리 상태를 저장장치로 옮기는데,
이를 코어 덤프(core dump)라고 한다.
코어 덤프는 종료 직전의 메모리 상태를 확인함으로써 오류를 수정할 수 있게 해준다.
```

### 4. 프로세스 휴식 상태와 보류 
<ul><li>휴식 상태</li></ul>

```
휴식 상태(Pause Status)는 프로세스가 작업을 일시적으로 쉬고 있는 상태이다.
```

<ul><li>보류 상태</li></ul>

```
보류 상태(Suspend Status)는 프로세스가 메모리에서 잠시 쫓겨난 상태로 휴식 상태와 차이가 있다.
보류 상태는 '일시 정지 상태'라고도 불리며, 보류 상태와 비교하여 일반적인 프로세스 상태를 활성 상태라고 한다.
보류 상태에 들어간 프로세스는 메모리 밖으로 쫓겨나 스왑 영역(swap area)에 보관된다.
스왑 영역은 메모리에서 쫓겨난 데이터가 임시로 보간되는 곳이다.
보류 상태와 휴식 상태를 구분하자면, 보류 상태는 스왑 영역에 있는 상태에고 휴식 상태는 프로세스가 메모리에 있으나 멈춘 상태이다.
```

### 5. 프로세스의 다섯 가지 상태 정리
<picture>
  <img alt="process 5state" src="https://blog.kakaocdn.net/dn/bf4d6d/btq1NuS4831/dbvf4a9ah1kXaLugrMhrNK/img.png">
</picture>

|상태|설명|작업|
|:---:|:---:|:---:|
|생성 상태|<ul><li>프로그램을 메모리에 가져와 실행 준비가 완료된 상태</li></ul>|메모리 할당, 프로세스 제어 블록 생성|
|준비 상태|<ul><li>실행을 기다리는 모든 프로세스가 자기 차례를 기다리는 상태</li></ul><ul><li>실행될 프로세스를 CPU 스케줄러가 선택</li></ul>|dispatch(PID) : 준비 -> 실행|
|실행 상태|<ul><li>선택된 프로세스가 타임 슬라이스를 얻어 CPU를 사용하는 상태</li></ul><ul><li>프로세스 사이의 문맥 교환이 일어남</li></ul>|timeout(PID) : 실행 -> 준비<br>exit(PID) : 실행 -> 완료<br>block(PID) : 실행 -> 대기|
|대기 상태|<ul><li>실행 상태에 있는 프로세스가 입출력을 요청하면 입출력이 완료될 때까지 기다리는 상태</li></ul><ul><li>입출력이 완료되면 준비 상태로 감</li></ul>|wakeup(PID) : 대기 -> 준비|
|완료 상태|<ul><li>프로세스가 종료된 상태</li></ul><ul><li>사용하던 모든 데이터가 정리됨</li></ul><ul><li>정상 종료인 exit와 비정상 종료인 abort를 포함</li></ul>|메모리삭제, 프로세스 제어 블록 삭제|

### 6. 프로세스 제어 블록(PCB) 

```
프로세스 제어 블록(PCB)은 프로세스를 실행하는 데 필요한 중요한 정보를 보관하는 자료 구조로 TCB(Task Control Block)라고도 한다.
모든 프로세스는 고유의 프로세스 제어 블록을 가지며, 프로세스 제어 블록은 프로세스 생성 시 만들어져서 프로세스가 실행을 완료하면 폐기된다.
```

### 6-1. 프로세스 제어 블록의 구성
<picture>
  <img src="구성도" src="https://blog.kakaocdn.net/dn/cjrby0/btqIarikobp/wPTdGGKemxiT7XkXXEBdQ0/img.png">
</picture>

|구성 요소|설명|
|:---:|:---:|
|포인터|<ul><li>프로세스 제어 블록의 첫 번째 블록에는 포인터가 저장됨</li></ul><ul><li>준비 상태나 대기 상태는 큐로 운영되는데, 프로세스 제어 블록을 연결하여 준비 상태나 대기 상태의 큐를 구현할 때 포인터를 사용</li></ul>|
|프로세스 상태|<ul><li>프로세스가 현재 어떤 상태에 있는지 나타냄</li></ul><ul><li>프로세스 제어 블록의 두 번째 블록에 저장됨</li></ul>|
|프로세스 구분자|<ul><li>운영체제 내에 있는 여러 프로세스를 구별하기 위한 구분자를 저장</li></ul>|
|프로그램 카운터|<ul><li>다음에 실행될 명령어의 위치를 가리키는 프로그램 카운터의 값을 저장</li></ul>|
|프로세스 우선순위|<ul><li>높은 우선순위의 프로세스가 낮은 우선순위의 프로세스보다 먼저 실행되고 더 자주 실행되는데, 그 우선순위를 저장</li></ul>|
|각종 레지스터 정보|<ul><li>프로세스가 실행되는 중에 사용하던 레지스터(누산기, 색인 레지스터, 스택 포인터 등)의 값을 저장</li></ul><ul><li>이전에 실행할 때 사용한 레지스터의 값을 보관해야 다음에 실행할 수 있기 때문에 자신이 사용하던 레지스터의 중간값을 보관</li></ul>|
|메모리 관리 정보|<ul><li>메모리 위치 정보(프로세스가 메모리의 어디에 있는지 나타냄), 경계 레지스터 값과 한계 레지스터 값(메모리 보호를 위해 사용) 등을 저장</li></ul><ul><li>세그먼테이션 테이블, 페이지 테이블 등의 정보도 보관</li></ul>|
|할당된 자원 정보|<ul><li>프로세스를 실행하기 위해 사용하는 입출력 자원이나 오픈 파일 등에 대한 정보 저장</li></ul>|
|계정 정보|<ul><li>계정 번호, CPU 할당 시간, CPU 사용 시간 등의 정보를 저장</li></ul>|
|부모 프로세스 구분자와 자식 프로세스 구분자|<ul><li>PPID, CPID 정보를 저장</li></ul><ul><li>부모 - 자식 프로세스의 관계는 프로세스를 이해하는데 매우 중요</li></ul>|

> 세그먼테이션 테이블, 페이지 테이블은 뒤에서 다시 다룸

## 스레드(Thread)
### 1. 스레드란?

<picture>
  <img src="스레드" src="https://blog.kakaocdn.net/dn/cjrby0/btqIarikobp/wPTdGGKemxiT7XkXXEBdQ0/img.png">
</picture>

```
프로세스의 코드에 정의 절차에 따라 CPU에 작업 요청을 하는 실행 단위
```

* 특징
  * 스레드는 프로세스 내에서 각각 Stack만 따로 할당받고 Code, Data, Heap 영역은 공유
  * 스레드는 한 프로세스 내에서 동작되는 여러 실행의 흐름으로, 프로세스 내의 주소 공간이나 자원들(힙 공간 등)을 같은 프로세스 내에 스레드끼리 공유하면서 실행
  * 같은 프로세스 안에 있는 여러 스레드들은 같은 힙 공간을 공유 / 프로세스는 다른 프로세스의 메모리에 직접 접근 X
  * 각각의 스레드는 별도의 레지스터와 스택을 갖고 있지만, 힙 메모리는 서로 읽고 쓸 수 있음
  * 한 스레드가 프로세스 자원을 변경하면, 다른 이웃 스레드도 그 변경 결과를 즉시 볼 수 있음

### 2. 스택을 스레드마다 독립적으로 할당하는 이유

```
스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는것 -> 독립적인 실행 흐름이 추가되는 것
스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소조건으로 독립된 스택을 할당
```

### 3. PC Register를 스레드마다 독립적으로 할당하는 이유

```
스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당함
명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있음
따라서 PC Register를 독립적으로 할당
```

## 멀티 스레드
### 1. 헷갈리기 쉬운 스레드 관련 용어 정리
|스레드 용어|설명|
|:---:|:---:|
|멀티스레드|<ul><li>운영체제가 소프트웨어적으로 프로세스 내 작업을 여러 개의 스레드로 분할함으로써 작업의 부담을 줄이는 프로세스 운영 기법</li></ul>|
|멀티태스킹|<ul><li>운영체제가 CPU에 작업을 줄 때 시간을 잘게 나누어 배분하는 기법</li></ul><ul><li>여러 스레드에 시간을 잘게 나누어주는 시스템을 시분할 시스템(time-sharing system)이고 CPU에 전달하는 작업은 스레드</li></ul>|
|멀티프로세싱|<ul><li>하나의 응용프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 하나의 작업(Task)을 처리하도록 하는 것</li></ul><ul><li>CPU를 여러 개 사용하여 여러 개의 스레드를 동시에 처리하는 작업 환경</li></ul><ul><li>하나의 컴퓨터에 여러 개의 CPU, 하나의 CPU 내 여러 개의 코어에 스레드 배정, 네트워크로 연결된 여러 컴퓨터에 스레드를 나누어 협업하는 분산시스템 => 멀티프로세싱</li></ul>|
|CPU 멀티스레드|<ul><li>하드웨어적인 방법으로 하나의 CPU에서 여러 스레드를 동시에 처리하는 병렬 처리 기법</li></ul>|

### 2. 멀티 스레딩의 장점

```
프로세스는 크게 정적인 영역과 동적인 영역으로 구분된다. 
여러 개의 프로세스를 만들면 필요없는 정적 영역이 여러 개가 된다. 
이 문제를 해결하기 위해 하나의 프로세스 내에 여러 개의 스레드를 생성하는 멀티스레드는 
코드, 파일 등의 자원을 공유함으로써 자원의 낭비를 막고 효율성을 향상한다.
```

<picture>
  <img src="멀티스레드" src="https://jaeseongdev.github.io/assets/img/posts/development-os/2021-06-16-%EB%A9%80%ED%8B%B0%EC%8A%A4%EB%A0%88%EB%93%9C%2C%20%EB%A9%80%ED%8B%B0%EC%93%B0%EB%A0%88%EB%93%9C%20%3A%20%20%EB%A9%80%ED%8B%B0%20%ED%83%9C%EC%8A%A4%ED%82%B9%20%3A%20%EB%A9%80%ED%8B%B0%20%ED%94%84%EB%A1%9C%EC%84%B8%EC%8B%B1%20%3A%20%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80%20%EC%8A%A4%EB%A0%88%EB%93%9C%EC%9D%98%20%EC%B0%A8%EC%9D%B4/Untitled.png">
</picture>

|멀티 스레딩의 장점|설명|
|:---:|:---:|
|응답성 향상|<ul><li>한 스레드가 입출력으로 인해 작업이 진행되지 않더라도 다른 스레드가 작업을 계속하여 사용자의 작업 요구에 빨리 응답할 수 있음</li></ul>|
|자원 공유|<ul><li>한 프로세스 내에서 독립적인 스레드를 생성하면 프로세스가 가진 자원을 모든 스레드가 공유하게 되어 작업을 원활하게 진행할 수 있음</li></ul>|
|효율성 향상|<ul><li>여러 개의 프로세스를 생성하는 것과 달리 불필요한 자원의 중복을 막음으로써 시스템의 효율이 향상됨</li></ul>|
|다중 CPU 지원|<ul><li>2개 이상의 CPU를 가진 컴퓨터에서 사용하면 다중 CPU가 멀티스레드를 동시에 처리하여 CPU 사용량이 증가하고 프로세스의 처리 시간이 단축됨</li></ul>|

### 3. 멀티스레딩의 문제점
* 주의 깊은 설계가 필요함
* 디버깅이 까다로움
* 단일 프로세스 시스템의 경우 효과를 기대하기 어려움
* 다른 프로세스에서 스레드를 제어할 수 없음(즉, 프로세스 밖에서 스레드 각각을 제어할 수 없음)
* 멀티 스레드의 경우 자원 공유의 문제가 발생(동기화 문제)
* 하나의 스레드에 문제가 발생하면 전체 프로세스가 영향을 받음

> 이해하기 쉬운 예 : 인터넷 익스플로어(멀티 스레드) vs 크롬(멀티 태스킹)
> 
> 인터넷 익스플로어는 하나의 탭이 문제 생기면 익스플로어 자체가 종료됨
> 
> 크롬은 하나의 탭이 문제 생겨도 문제 있는 탭만 종료할 수 있음
> 
### 4. 멀티 프로세스의 장점
* 여러 개의 자식 프로세스 중 하나에 문제가 발생하면 그 자식 프로세스만 죽은 것 이상으로 다른 영향이 확산되지 않음

### 5. 멀티 프로세스의 문제점
|멀티 프로세스의 문제점|설명|
|:---:|:---:|
|Context Switching(문맥 교환)에서의 오버헤드|<ul><li>Context Switching 과정에서 캐시 메모리 초기화 등 무거운 작업이 진행되고 많은 시간이 소모되는 등의 오버헤드가 발생하게 됨</li></ul><ul><li>프로세스는 각각의 독립된 메모리 영역을 할당받았기 때문에 프로세스 사이에서 공유하는 메모리가 없어, Context Switching이 발생하면 캐시에 있는 모든 데이터를 모두 리셋하고 다시 캐시 정보를 불러와야 함</li></ul>|
|프로세스 사이의 어렵고 복잡한 통신 기법(IPC)|<ul><li>프로세스는 각각의 독립된 메모리 영역을 할당받았기 때문에 하나의 프로그램에 속하는 포르세스들 사이의 변수를 공유할 수 없음</li></ul>|

### 6. 멀티 스레드 vs 멀티 프로세스
|멀티 스레드|멀티 프로세스|
|:---:|:---:|
|적은 메모리 공간 차지 -> Context Switching 빠름|비교적 많은 메모리 공간 차지 -> Context Switching 느림|
|하나의 스레드 장애로 전체 스레드가 종료될 위험|하나의 스레드 장애로 전체 스레드가 종료될 위험 X|

* 멀티 프로세스로 할 수 있는 작업들을 하나의 프로세스에서 스레드로 나눠가며 하는 이유
  * 운영체제가 시스템 자원을 효율적으로 관리하기 위해 스레드를 사용
  * 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리 가능
  * 프로세스 간의 통신보다 스레드 간의 통신 비용이 적기 때문에 작업들 간 통신의 부단이 줄어듬(프로세스는 독립구조 -> 처리비용 감소)

## 스케줄러
### 1. 장기 스케줄러
* 시스템 내의 전체 작업 수를 조절하는 스케줄러 -> 풀(pool)로부터 프로세스들을 선별하고 실행을 위해 메모리에 적재
* 어떤 작업(운영체제에서 다르는 일의 가장 큰 단위로, 1개 또는 여러 개의 프로세스로 이루어짐)을 시스템이 받아들일지 또는 거불할지를 결정
* 장기 스케줄러에 의해 시스탬 내에서 동시에 실행 가능한 프로세스의 총 개수가 정해짐
* 고수준 스케줄러, 작업 스케줄러, 승인 스케줄러, CPU 스케줄러과 같은 의미

### 2. 단기 스케줄러
* 어떤 프로세스에 CPU를 할당할지, 어떤 프로세스를 대기 상태로 보낼지 등을 결정 -> 실행이 준비된 프로세스들 중 하나를 선별해 CPU에 할당
* 프로세스 상태에 관한 내용은 대부분 여기에 해당
* 저수준 스케줄링과 같은 의미

### 3. 중기 스케줄러
* 중지(suspend, 보류상태로 넘어감)와 활성화(active)로 전체 시스템의 활성화된 프로세스 수를 조절하여 과부하를 막음
* Swapper, 중간 수준 스케줄링과 같은 의미

## CPU 스케줄러
### 1. 선점형 & 비선점형
* 선점형 스케줄링 : 어떤 프로세스가 CPU를 할당받아 실행 중이더라도 운영체제가 CPU를 강제로 빼앗을 수 있는 스케줄링 방식
* 비선점형 스케줄링 : 어떤 프로세스가 CPU를 점유하면 다른 프로세스가 이를 빼앗을 수 없는 스케줄링 방식

|구분|종류|
|:---:|:---:|
|비선점형 알고리즘|FCFS 스케줄링, SJF 스케줄링, HRN 스케줄링|
|선점형 알고리즘|Round Robin 스케줄링, SRT 스케줄링, 다단계 큐 스케줄링, 다단계 피드백 큐 스케줄링|
|둘 다 가능|우선순위 스케줄링|

### 2. FCFS(First Come First Served)

```
준비 큐에 도착한 순서대로 CPU를 할당하는 비선점형 방식으로, 선입선출 스케줄링이라고도 한다.
```

<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-56.png">
</picture>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-57.png">
</picture>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-58-768x257.png">
</picture>

* 장점
  * 단순하고 공평함

* 단점
  * 처리 시간이 긴 프로세스가 CPU를 차지하면 다른 프로세스들은 하엽없이 기다려 시스템의 효율성이 떨어지는 문제 발생 => 콘보이 효과 or 호위 효과
  * 현재 작업 중인 프로세스가 입출력 작업을 요청하는 경우 CPU가 작업하지 않고 쉬는 시간이 많아져 작업 효율이 떨어짐

### 3. SJF(Shortest - Job - First)

```
준비 큐에 있는 프로세스 중에서 실행 시간이 가장 짧은 작업부터 CPU를 할당하는 비선점형 방식으로, 최단 작업 우선 스케줄링이라고도 한다.
```

> FCFS 스케줄링의 콘보이 효과를 완화하여 시스템의 효율성을 높인 것<br>
> SPF(Shortest Process First), 최단 프로세스 우선 스케줄링과 같은 말

<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-60.png">
</picture><br>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-61.png">
</picture><br>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-63.png">
</picture>

* 장점
  * 작은 작업을 먼저 실행하기 때문에 시스템의 효율성이 좋아짐

* 단점
  * 운영체제가 프로세스 종료 시간을 정확하게 예측하기 어려움
    - 현대의 프로세스는 사용자와의 상호작용이 빈번하게 발생하기 때문
  * 공평하지 않음
    - 먼저 도착해도 늦게 실행되는 프로세스가 있음
    - 작업이 계속 연기되는 현상 발생 => 아사현상(starvation) or 무한 봉쇄 현상(infinite blocking) 발생

* 단점 해결책
  * 프로세스가 자신의 작업 시간을 운영체제에 알려주어 해결
    - 프로세스가 자신의 작업 시간을 정확히 알기 어려움
    - 일부 악의적인 프로세스가 작업 시간을 속인다면 시스템의 효율성이 나빠짐
  * 에이징(나이먹기, aging)으로 완화할 수 있음
    - 프로세스가 양보할 수 있는 상한선을 정하는 방식
    - 에이징 값을 어떤 기준으로 정할 것인지가 문제

### 4. SRTF(Shortest Remaining Time First)

```
선점형 SJF 스케줄링 개념이다.
```

<picture>
  <img src="https://blog.kakaocdn.net/dn/47cG3/btqF63ctwKv/99wazY0GKJGkY5jUxCMoRk/img.png">
</picture>

* 단점
  * 아사현상(starvation)이 발생

### 5. Priority Scheduling

```
프로세스는 중요도에 따라 우선순위(Priority)를 갖는데 이러한 우선순위를 반영한 스케줄링 알고리즘
```

* 고정 & 변동
  * 고정 우선순위 알고리즘 
    - 한 번 우선순위를 부여받으면 종료될 때까지 우선순위가 고정됨
    - 단순하게 구현할 수 있지만 시시각각 변하는 시스템의 상황을 반영하지 못해 효율성이 떨어짐
  * 변동 우선순위 알고리즘 
    - 일정 시간마다 우선순위 변함
    - 일정 시간마다 우선순위를 새로 계산하고 이를 반영하기 때문에 시스템이 복잡하지만 시스템의 상황을 반영하여 효율적인 운영이 가능

* 적용 예시
  * (비선점형 방식)SJF 스케줄링 : 작업 시간이 짧은 프로세스에 높은 우선순위를 부여함
  * (비선점형 방식)HRN 스케줄링 : 작업 시간이 짧거나 대기 시간이 긴 프로세스에 높은 우선순위를 부여함
  * (선점형 방식)SRT 스케줄링 : 남은 시간이 짧은 프로세스에 높은 우선순위를 부여함

* 평가
  * 준비 큐에 있는 프로세스의 순서를 무시하고 우선순위가 높은 프로세스에 먼저 CPU를 할당 -> 공평성을 위배하고 아사 현상을 일으킴
  * 준비 큐에 있는 프로세스의 순서를 무시하고 프로세스의 우선순위를 매번 바꿔야 함 -> 오버헤드가 발생하여 시스템의 효율성을 떨어뜨림
  * 우선순위는 시스템의 효율성 보다 프로세스의 중요도에 따라 정해짐

### 6. Round Robin

```
한 프로세스가 할당받은 시간(타임 슬라이스)동안 작업을 하다가 작업을 완료하지 못하면 준비 큐의 맨 뒤로 가서 자기 차례를 기다리는 방식
선점형 알고리즘 중 가장 단순하고 대표적인 방식으로, 프로세스들이 작업을 완료할 때까지 계속 순환하면서 실행
```
> FCFS 스케줄링과 유사한데, 각 프로세스마다 CPU를 사용할 수 있는 최대 시간, 즉 타임 슬라이스 존재

<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-72.png">
</picture><br>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-73.png">
</picture><br>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-74.png">
</picture>

* 장점
  * 프로세스가 CPU를 일정 시간 동안 사용한 후 다른 프로세스에 주어야 하기 때문에 콘베이 효과가 줄어듬

* 단점
  * 타임 슬라이스가 큰 경우
    - FCFS 스케줄링과 다를 게 없음
  * 타임 슬라이스가 작은 경우
    - 문맥 교환이 너무 자주 일어나 시스템의 전반적인 성능이 떨어짐

* 타임 슬라이스는 되도록 작게 설정하되 문맥 교환에 걸리는 시간을 고려하여 적당한 크기로 하는 것이 중요

## 동기(Synchronous)와 비동기(Asynchronous) 및 Blocking 과 Non-Blocking
Synchronous와 Asynchronous는 **작업을 수행하는 주체에 대한 관점**<br>Blocking과 Non-Blocking은 **제어권이 어디에 있느냐에 대한 관점**
### 1. 동기(Synchronous)

```
두 개 이상의 주체가 작업 시간을 똑같이 맞출 때
답변을 기다리는 것
```

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2F1e696752-5f8c-43b2-8cf4-4cc513762189%2Fimage.png">
</picture>

> A가 끝나는 시간과 B가 시작하는 시간을 맞추면 Synchronous(동기)<br>
> ex) JAVA - synchronized, BlockingQueue

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2Fb50808ff-b090-4396-a3fd-4e284908fdde%2Fimage.png">
</picture>

> A와 B가 시작시간 또는 종료시간이 일치하면 Synchronous(동기)<br>
> ex) JAVA - CyclicBarrier

### 2. 비동기(Asynchronous)

```
두 개 이상의 주체가 작업 시간을 서로 맞추지 않을 때
답변을 기다리지 않는 것
```

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2F8d93245e-e316-4502-9774-ccae1b752636%2Fimage.png">
</picture>

> 각자 별도의 시작시간, 끝나는 시간을 가지고 있으면 Asynchronous(비동기)<br>
> 두 가지 이상의 대상이 서로 시간을 맞춰 행동하지 않는 것
> 시킨 일을 다 했는지 물어보는 것은 polling

### 3. Blocking

```
직접 제어할 수 없는 대상의 작업이 끝날 때까지 기다려야 하는 경우
```

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2Ff87c23bc-2194-4245-8212-6879b975bb2f%2Fimage.png">
</picture>

> 개발 부서 전체 작업의 제어권을 가진 팀장이 엔지니어 A에게 제어권을 넘김<br>
> 엔지니어 A가 작업을 수행할 동안 개발 부서 전체는 이를 기다림<br>
> 엔지니어 A가 작업을 마치고 팀장에게 알리면서 동시에 제어권도 돌려줌<br>
> 제어권이 없는 상태 => **Blocking**이 되며 다른 일을 할 수 없는 상태가 됨

### 4. Non-Blocking

```
직접 제어할 수 없는 대상의 작업이 완료되기 전에 제어권을 넘겨주는 경우
```

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2F1ad8b445-869d-49d9-925f-5ef7dd9cff28%2Fimage.png">
</picture>

> 제어권을 바로 팀장에게 돌려주기 때문에 개발 부서는 엔지니어 A의 작업을 기다리지 않음 -> 다른 일을 할 수 있는 상태가 됨

## 동시성 문제
### 1. Critical Section(임계영역)

```
공유 자원 접근 순서에 따라 실행 결과가 달라지는 프로그램의 영역
```

* 프로세스 간에 공유자원을 접근하는 데 있어서 문제가 발생하지 않도록 한 번에 하나의 프로세스만 이용하게끔 **보장**해줘야 하는 영역

> ex) 예금을 확인하고 입금을 한 후 예금을 저장하는 부분

### 1-1. Critical Section(임계 영역) 문제 해결 3가지 조건

* **상호 배제(Mutual exclution)** : 한 프로세스가 임계 영역에 들어가면 다른 프로세스는 임계 여역에 들어갈 수 없다.
* **한정 대기(Bounded wating)** : 어떤 프로세스도 무한 대기(infinite postpone)하지 않아야 한다. 
                         -> 한 번 임계 영역에 들어간 프로세스는 다음번 임계 영역에 들어갈 떄 제한을 두어야 한다.
* **진행의 융통성(Progress)** : 요리사 B는 요리사 A의 작업 속도와 관계없이 믹서가 비어 있으면 언제든 사용 가능 
                      -> 한 프로세스가 다른 프로세스의 진행을 방해해서는 안된다.
                      
### 2. Race Condition(경쟁 상태)

```
공유 자원에 대해 여러 프로세스가 동시에 접근을 시도할 떄, 타이밍이나 순서 등이 결과값에 영향을 줄 수 있는 상태
```

> ex) 프로세스 p1이 예금하고 프로세스 p2가 동시에 예금했을 때 총액의 결과

### 3. Deadlock(교착 상태)

```
2개 이상의 프로세스가 다른 프로세스의 작업이 끝나기만 기다리며 작업을 더 이상 진행하지 못하는 상태
```

> 프로세스가 자원을 사용하는 절차 : Request, Allocate, Use, Release<br>
> Request : 자원을 요청하고, 만약 다른 프로세스가 자원을 사용하고 있어 받을 수 없다면 대기<br>
> Allocate : 자원을 받음<br>
> Use : 프로세스가 받은 자원을 사용<br>
> Release : 프로세스가 자원을 놓아줌<br><br>
> Deadlock은 모든 프로세스가 Request인 상태

🚀 Deadlock vs Starvation

* Deadlock : 여러 프로세스가 작업을 진행하다 보니 자연적으로 일어나는 문제 -> 강압적으로 해결
* Starvation : 운영체제가 잘못된 정책을 사용하여 특정 프로세스의 작업이 지연되는 문제

### 4. Deadlock 발생 조건(필요 충분 조건)

Deadlock이 발생하기 위해선 다음 4가지 조건을 만족해야 한다.

> 자원이 가지는 특징
* **상호 배제** : 한 프로세스가 사용하는 자원은 다른 프로세스와 공유할 수 없는 배타적인 자원이어야 한다.
* **비선점** : 한 프로세스가 사용 중인 자원은 중간에 다른 프로세스가 빼앗을 수 없는 비선점 자원이어야 한다.

> 프로세스의 행위
* **점유와 대기** : 프로세스가 어떤 자원을 할당받은 상태여서 다른 자원을 기다리는 상태여야 한다.
* **원형 대기** : 점유와 대기를 하는 프로세스 간의 관계가 원을 이루어야 한다. -> 사이클이 있다면 Deadlock, 없다면 X

### 5. Deadlock 해결 방법

|해결 방안|특징|
|:---:|:---:|
|교착 상태 예방|교착 상태를 유발하는 네 가지 조건을 무력화|
|교착 상태 회피|교착 상태가 발생하지 않는 수준으로 자원을 할당|
|교착 상태 검출|자원 할당 그래프를 사용하여 교착 상태를 발견|
|교착 상태 회복|교착 상태를 검출한 후 해결|

### 5-1. 교착 상태 예방

* 상호 배제 예방
  - 독점적으로 사용할 수 있는 자원을 없애는 방법
  - 현실적으로는 모든 자원을 공유할 수 없으며 상호 배제를 적용하여 보호해야 하는 자원이 있음
  - 상호 배제를 무력화하는 것은 사실상 어려움
* 비선점 예방
  - 모든 자원을 빼앗을 수 있도록 만드는 방법
  - 임계 영역을 보호하기 위해 잠금을 사용하면 자원을 빼앗을 수 없고 상호 배제도 보장할 수 없음 -> 사실상 모든 자원을 빼앗을 수 없음
  - 어떤 기준으로 빼앗을지, 얼마나 사용할지 결정하기 어려워 아사 현상을 일으킴
  - 에이징을 사용해도 다시 비선점 자원이 되어 다시 교착상태에 빠질 수 있음
* 점유와 대기 예방
  - 프로세스가 자원을 점유한 상태에서 다른 자원을 기다리지 못하게 하는 방법 -> 전부 할당하거나 할당하지 않거나(all or nothing)
  - 자원이 아닌 프로세스의 자원 사용 방식을 변화시켜 해결하는 점에서 의의가 있음

  * 단점
  - 프로세스가 자신이 사용하는 모든 자원을 자세히 알기 어려움 : 추가로 필요한 자원이 생기면 이를 다시 확보하기 어려움
  - 자원의 활용성이 떨어짐 : 당장 사용하지도 않을 자원을 미리 선점하여 자원 낭비가 심함
  - 많은 자원을 사용하는 프로세스가 적은 자원을 사용하는 프로세스보다 불리함
  - 결국 일괄 작업 방식으로 동작함
* 원형 대기 예방
  - 점유와 대기를 하는 프로세스들이 원형을 이루지 못하도록 막는 방법
  - 모든 자원에 숫자를 부여하고 숫자가 큰 방향으로만 자원을 할당
  
  * 단점
    - 프로세스 작업 진행에 유연성이 떨어짐
    - 자원의 번호를 어떻게 부여할 것인지가 문제

### 5-2. 교착 상태 회피

* 프로세스에 자원을 할당할 떄 어느 수준 이상의 자원을 나누어주면 교착 상태가 발생하는지 파악하여 그 수준 이하로 자원을 나누어주는 방법

대표적인 예로 **은행원 알고리즘**이 있다.

#### 은행원 알고리즘

|변수|설명|
|:---:|:---:|
|전체 자원(Total)|시스템 내 전체 자원의 수|
|가용 자원(Available)|시스템 내 현재 사용할 수 있는 자원의 수(가용 자원 = 전체 자원 - 모든 프로세스의 할당 자원)|
|최대 자원(Max)|각 프로세스가 선언한 최대 자원의 수|
|할당 자원(Allocation)|각 프로세스에 현재 할당된 자원의 수|
|기대 자원(Expect)|각 프로세스가 앞으로 사용할 자원의 수(기대 자원 = 최대 자원 - 할당 자원)|

* 자원 할당 기준
  - 기대 자원(Expect) <= 가용 자원(Allocation) -> 자원할당 : 자원을 사용하여 작업을 끝낼 수 있는 프로세스가 있다는 의미이므로 안정 상태
  - 기대 자원(Expect) > 가용 자원(Allocation) -> 자원할당 X : 자원을 사용하여 작업을 마칠 수 있는 프로세스가 없다는 의미이므로 불안정 상태
 
<picture>
  <img src="https://velog.velcdn.com/images%2Fsunil1369%2Fpost%2F7fb02580-b268-4cf0-9d60-dbf4ee029ad7%2Fimage.png">
</picture>

* 문제점
  - 프로세스가 자신이 사용할 모든 자원을 미리 선언해야 한다.
  - 시스템의 전체 자원 수가 고정적이어야 한다.
  - 자원이 낭비된다.
  
### 5-3. 교착 상태 검출

* 운영체제가 프로세스의 작업을 관찰하면서 교착 상태 발생 여부를 계속 주시하는 방식
* 교착 상태가 발견되면 교착 상태 회복 단계로

#### 타임아웃 -> '가벼운 교착 상태 검출'

* 일정 시간 동안 작업이 진행되지 않은 프로세스를 교착 상태가 발생한 것으로 간주하여 처리하는 방법
> ex) 윈도우에서 '프로그램이 응답이 없어 종료합니다' 메시지

<picture>
  <img src="https://velog.velcdn.com/images%2Fkwt0124%2Fpost%2F1cd7f74a-7a83-444a-b122-087212a25ce6%2Fimage.png">
</picture>

> 타임아웃으로 데이터의 일관성이 깨지는 문제를 해결하기 위해 데이터베이스에서 사용하는 체크포인트와 롤백<br>
> 저장된 데이터 : 스냅숏

* 문제점
  - 엉뚱한 프로세스가 강제 종료될 수 있다.
  - 모든 시스템에 적용할 수 없다.(분산 데이터베이스 등) 

#### 자원 할당 그래프 -> '무거운 교착 상태 검출'

* 그래프를 통해 교착 상태가 있는지 없는지 판단하는 방법

<picture>
  <img src="https://t1.daumcdn.net/cfile/tistory/99512D345BFD21B92B">
</picture>

> 장점 : 프로세스의 작업 방식을 제한하지 않으면서 교착 상태를 정확하게 파악할 수 있다<br>
> 단점 : 자원 할당 그래프를 유지하고, 갱신하고, 사이클을 검사하는 추가 작업으로 인해 오버헤드가 발생한다.
> 이러한 추가 작업을 줄이기 위해 자원이 할당될 때마다 사이클 검사를 하는 것이 아니라 일정 시간마다 하는 방법도 있다.

### 5-4. 교착 상태 회복

```
교착 상태를 푸는 후속 작업
교착 상태를 유발한 프로세스를 강제로 종료
강제 종료된 프로세스가 실행되기 전에 시스템을 복구
명령어가 실행될 때마다 체크포인트를 만들어 가장 최근의 검사 시점으로 돌아감
작업량이 상당하여 시스템에 부하를 주므로 체크포인트를 무분별하게 사용X
```

> 종료하는 방법 2가지

* 교착 상태를 일으킨 모든 프로세스를 동시에 종료
  - 다시 교착 상태를 일으킬 가능성이 큼
  - 강제 종료 후 순차적으로 실행
  - 어떤 프로세스를 먼저 실행할 것인지 기준 필요
  
* 교착 상태를 일으킨 프로세스 중 하나를 골라 순서대로 종료
  - 우선순위가 낮은 프로세스를 먼저 종료
  - 우선순위가 같은 경우 작업 시간이 짧은 프로세스를 먼저 종료
  - 위의 두 조건이 같은 경우 자원을 많이 사용하는 프로세스를 먼저 종료

## 메모리 관리 전략
### 1. 물리 메모리

> 물리 메모리 분할 방식

|구분|가변 분할 방식|고정 분할 방식|
|:---:|:---:|:---:|
|메모리 단위|세그먼테이션|페이징|
|특징|연속 메모리 할당|비연속 메모리 할당|
|장점|프로세스를 한 덩어리로 관리 가능|메모리 관리가 편리|
|단점|빈 공간의 관리가 어려움|프로세스가 분할되어 처리됨|
|단편화|외부 단편화|내부 단편화|

> 메모리가 할당되고 해제되는 작업이 반복될 때 작은 메모리 중간중간 사용하지 않는 메모리가 많이 존재해서<br>
> 총 메모리 공간은 충분하지만 실제로 할당할 수 없는 문제를 External fragmentation, 외부 단편화라고 한다.<br>
>
> 비어있는 공간을 연속적인 공간으로 만들고 움직이는 작업을 Compaction(Paging의 배경)이라고 한다.

> 일정하게 나뉜 메모리의 크기보다 작은 프로세스가 배치될 경우 낭비되는 공간이 생기는 것을 Internal fragment, 내부 단편화라고 한다.

### 2. 가상 메모리

```
물리 메모리의 크기와 프로세스가 올라갈 메모리의 위치를 신경 쓰지 않고 프로그래밍하는 시스템
```

* 가상 메모리에서 메모리 관리자가 사용할 수 있는 메모리의 전체 크기는 물리 메모리(실제 메모리)와 스왑 영역을 합한 크기이다.
* 즉, 가상 메모리 크기 = 물리 메모리 + 스왑 영역

* 동적 주소 변환(dynamic Address Translation, DAT) : 메모리 관리자가 물리 메모리와 스왑 영역을 합쳐서 프로세스가 사용하는 가상 주소를 실제 메모리의 물리 주소로 변환하는 작업

|구분|가상 메모리|물리 메모리|
|:---:|:---:|:---:|
|최대 메모리 크기|CPU의 비트 값에 의존|CPU의 비트 값에 의존|
|메모리 분할 방식|세그먼테이션|가변 분할 방식|
|메모리 분할 방식|페이징|고정 분할 방식|
|메모리 분할 방식|세그먼테이션-페이징 혼용 기법||
|주소 지정 방식|가상 주소|절대 주소, 상대 주소|

### 3. Paging(페이징)

> Page vs Frame
* Page : Logical address space를 동일한 크기로 나눈 것
* Frame : Physical memory를 나눈 것

```
고정 분할 방식을 이요한 가상 메모리 관리 기법
물리 주소 공간을 같은 크기로 나누어 사용 
```

<picture>
  <img src="https://media.vlpt.us/images/chappi/post/18f268bd-8da3-492a-b672-4f942a138294/3.png">
</picture>

* 첫번째 칸 2는 페이지 0이 프레임 2에 있다는 의미
* 페이지 5는 물리 메모리에 없기 때문에 페이지 테이블에 invalid(스왑 영역에 있다는 의미)라고 표시

* 내부 단편화는 생길 수 있음

### 4. Segmentation(세그멘테이션)

```
가변 분할 방식을 이용한 가상 메모리 관리 기법
물리 메모리를 프로세스의 크기(내용)에 따라 가변적으로 나누어 사용
```

> limit & address
* limit : 세그먼트의 크기를 나타냄 / 세그먼트가 자신에게 주어진 메모리 영역을 넘어가면 안되기 때문
* address : 물리 메모리상의 시작 주소를 나타냄

<picture>
  <img src="https://media.vlpt.us/images/chappi/post/fbec6326-787d-4c2b-8e67-0d10d1744311/1.png">
</picture>

> 만약 사용자가 프로세스보다 더 큰 주소에 접근하려고하면, 메모리 관리자는 해당 프로세스를 강제 종료하는데, 이때 발생하는 오류를 **트랩(trap)** 이라고 한다.<br>
> 트랩이 발생하면 운영체제는 사용자에게 세그멘테이션 오류(segmentation fault) 메시지를 보낸다.

> 트랩과 반대로 사용자가 강제로 Ctrl+C 키를 눌러 프로세스를 중지시키는 것과 같이 의도한 인터럽트를 **시그널(signal)** 이라고 하고 외부 인터럽트 중 하나이다.

## 가상 메모리
### 1. Virtual Address Space(가상 주소 공간)

```
각각 프로세스에 주어지는 논리적인 공간
물리 메모리(RAM)의 크기와는 독립적이며, 레지스터 크기에 종속적
```

> 가상 주소 공간의 구조

<picture>
  <img src="https://wayhome25.github.io/assets/post-img/cs/virtual_address_space2.png">
</picture>

* code 영역 : 코드를 어셈블리어로 바꾸어 저장하는 공간
* data 영역 : 전역변수, static 변수의 할당을 위해 존재하는 공간
* heap 영역 : 프로그래머의 동적 할당을 위해 존재하는 공간
* stack 영역 : 지역 변수가 저장되는 공간

### 2. 프로세스간의 페이지 공유

> 프로세스 간 통신(Inter-Process Communication, IPC) : 프로세스 간에 서로 데이터를 주고 받는 행위 또는 그에 대한 방법이나 경로

* Shared Memory(공유 메모리)
  - 프로세스의 메모리 영역은 다른 프로세스가 접근해서 함부로 데이터를 읽거나 쓰지 못하도록 커널에 의해 보호
  - 메모리 영역을 침범하려고 하면 침범 프로세스에 SIGEGV(경고 시그널)을 보냄
  - 프로세스가 공유 메모리 할당을 커널에 요청하면 커널은 해당 프로세스에 다른 프로세스들과 공유할 수 있는 특수한 메모리 공간을 할당
  - 이후 어떤 프로세스든 해당 메모리 영역에 접근 가능
  - 중계자 없이 곧바로 메모리에 접근할 수 있어서 가장 빠르게 작동

### 3. Demand Paging(요구 페이징)

```
사용자가 요구할 때 해당 페이지를 메모리로 가져오는 것
```
> 가져오기 정책 : 프로세스가 필요로 하는 데이터를 언제 메모리로 가져올지 결정하는것<br>
> 요구 페이징 : 가져오기 정책 중 프로세스가 요청할 때 메모리로 가녀오는 방법(일반적임) 
> ex) 포토샵 대형 프로그램 & 피부 보정 필터, 노이즈 제거 필터 등

* 장점
  * 메모리 절약
  * 메모리의 효율적 관리
  * 프로세스의 응답 속도 향상

* 캐시
  * 요구 페이징과 반대로 앞으로 필요할 것이라고 예상되는 페이지를 미리 가져오는 방식
  * 미리 가져온 데이터가 쓸모없을 경우 피해가 매우 큼 -> 현대의 운영체제는 요구 페이징을 기본으로 사용

* 순수한 스와핑(swapping) : 프로세스를 구성하는 모든 페이지를 메모리에 올리는 것
* 게으른 스와핑(lazy swapping) : 사용자가 요구할 때 메모리에 올리는 것

### 4. Page fault trap(페이지 부재 트랩)

```
프로세스가 invalid page를 접근하면 MMU가 trap을 발생시킴
```

> Page fault
<picture>
  <img src="https://t1.daumcdn.net/cfile/tistory/2513314A55FE533722">
</picture>

1. 특정 페이지를 실행하기 위해 페이지 테이블 참조하여 메모리에 올라와 있는지 여부를 확인
2. 페이지가 메모리에 올라와 있지 않을 경우 MMU가 인터럽트
3. 운영체제는 해당 프로세스를 wait상태로 만들고 요구된 페이지를 하드디스크에서 찾아 메모리에 적재
4. 페이지 테이블 갱신
5. 해당 프로세스를 다시 ready -> running하여 작업 진행

* Page fault trap(페이지 부재 트랩) 발생 시 프로세스의 실행은 중단되고 필요한 페이지를 적재하는 입출력이 발생함
* 다른 프로세스가 CPU를 할당 받으며, 페이지 부재 처리가 완료 된 후에 인터럽트에 의해 중단된 프로세스가 재시작됨

## 페이지 교체

```
프로세스가 요구한 페이지가 현재 메모리에 없으면 페이지 부재가 발생
페이지 부재가 발생하면 스왑 영역에서 페이지를 메모리로 가져옴
만약 메모리가 꽉 찼다면 메모리에 있는 페이지를 스왑영역으로 내보내야 함
페이지 교체 알고리즘은 스왑 영역으로 보낼 페이지를 결정하는 알고리즘
메모리에서 앞으로 사용할 가능성이 적은 페이지를 대상 페이지로 선정하여
페이지 부재를 줄이고 시스템 성능을 향상
```

### 1. FIFO page replacement

```
시간상으로 메모리에 가장 먼저 들어온 페이지를 대상 페이지로 선정하여 스왑 영역으로 쫓아냄
```

<picture>
  <img src="https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%202.png">
</picture>

* 큐로 쉽게 구현 가능하지만 먼저 들어온 페이지를 항상 스왑 영역으로 옮김
* 시간의 지역성을 고려하면 가장 오래된 페이지를 대상 페이지로 선정하는 것이 맞음
* 그러나 메모리에 올라온 지 오래되었더라도 자주 사용하는 페이지가 있음
* 무조건 오래된 페이지를 대상 페이지로 선정하기 때문에 성능이 떨어짐

### 2. Optimal page replacement

```
앞으로 사용하지 않을 페이지를 스왑 영역으로 옮김
메모리가 앞으로 사용할 페이지를 미리 살펴보고 페이지 교체 선정 시점부터 사용 시점까지 가장 멀리 있는 페이지를 대상 페이지로 선정
```

<picture>
  <img src="https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%203.png">
</picture>

* 4번을 보자
* A는 6번에서, B는 5번에서, C는 9번에서 사용되므로 C가 스왑 영역으로 옮겨짐
* 미래의 메모리 접근 패턴을 보고 대상 페이지를 결정하기 때문에 성능이 좋음
* 미래의 접근 패턴을 안다는 것이 불가능하여 실제로 구현 X

### 3. Least Recently Used page replacement(LRU)

```
메모리에 올라온 후 가장 오랫동안 사용되지 않은 페이지를 스왑 영역으로 옮김
시간을 기준으로 구현할 수 있으며 카운터나 참조 비트를 이용하는 방법도 있음
```

<picture>
  <img src="https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%205.png">
</picture>

> 메모리에 올라오거나 사용될 때의 시간을 사각형 아래에 표시

* 6초의 경우 페이지 A를 올리기 위해 가장 오랫동안 접근하지 않았던 페이지 C를 스왑 영역으로 옮김

* 카운터에 기반하여 구현하는 것은 숫자를 시간(초)이 아니라 카운터 숫자로 바꾼 개념이다.
* 참조 비트 시프트 방식을 사용할 수도 있다.

<picture>
  <img src="https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%206.png">
</picture>

* 접근 횟수를 측정하는 LFU와 혼동할 수 있지만 시프트가 가장 많이 된 페이지를 스왑으로 넘기기 때문에 LRU이다.
* 접근 시간이나 참조 비트를 유지하기 위한 메모리가 추가로 필요하기 때문에 낭비되는 메모리 공간이 많다

### 4. Least Frequently Used page replacement(LFU)

```
페이지가 몇 번 사용되었는지를 기준으로 대상 페이지를 선정함
현재 프레임에 있는 페이지마다 그 동안 사용된 횟수를 세어 횟수가 가장 적은 페이지를 스왑 영역으로 옮김
```

<picture>
  <img src="https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%207.png">
</picture>

* 처음 메모리에 올라온 페이지의 사용 빈도가 1이고, 사용될 때마다 하나씩 증가한다.
* LRU, LFU 둘다 성능이 우수하고 FIFO보다 성능이 우수하다.
* LRU와 마찬가지로 낭비되는 메모리가 많다.(페이지 접근 횟수 표시)

### 5. Most Frequency Used(MFU)

```
LFU와 반대로 사용 횟수가 가장 많은 페이지를 스왑 영역으로 옮김
```

* 사용된 횟수가 적은 페이지가 최근에 사용된 것으로 보고 앞으로 사용될 가능성이 높다고 판단

## 동시성과 병렬성 차이

|동시성|병렬성|
|:---:|:---:|
|동시에 실행되는 것 같이 보이는 것|실제로 동시에 여러 작업이 처리되는 것|
|싱글 코어에서 멀티 스레드를 동작시키는 방식|멀티 코어에서 멀티 스레드를 동작시키는 방식|
|한번에 많은 것을 처리|한번에 많은 일을 처리|
|논리적인 개념|물리적인 개념|

* 동시성의 예 : 옛날 애니메이션을 만들때 하나로 이어진 것처럼 보이게 하기 위해서 여러번 끊은 화면을 이어 붙혔다.
